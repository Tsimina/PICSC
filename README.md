# PICSC

Integrated Cybersecurity Project for encrypted traffic analysis and application-level classification.
This project implements a machine-learning pipeline for encrypted network traffic classification, focusing on binary identification of Spotify traffic vs. non-Spotify traffic, without decrypting packet payloads.
The system extracts statistical and temporal flow-based features from PCAP files and evaluates multiple classical ML models (SVM, Random Forest, XGBoost) under different dataset and flow configurations.

## Table of contents 

- [Features](#features)
- [Repository structure](#repository-structure)
- [Dataset](#dataset)
- [Methodology](#methodology)
- [Feature Extraction](#feature-extraction)
- [Model Details](#model-details)
- [Requirements](#requirements)
- [Installation](#installation)
- [Usage](#usage)
- [Performance](#performance)
- [Limitation](#limitation)
- [Acknoledgments](#acknoledgments)

## Features

- Binary classification of **encrypted network traffic**
- **Spotify vs. non-Spotify** traffic identification
- Flow-based analysis (no payload inspection)
- Automatic PCAP → CSV feature extraction
- Classical ML models:
  - Support Vector Machine (SVM)
  - Random Forest (RF)
  - XGBoost
- Evaluation on:
  - Balanced datasets (Spotify : non-Spotify ≈ 1 : 1)
- Comparison of **active flow aggregation windows** (15s vs. 60s)
- Metrics:
  - Accuracy
  - F1 score
  - Confusion matrix
 
## Repository Structure

```text
## Repository Structure

```text
PICSC/
│
├── extracted_features/
│   ├── dataset_base_features/     # Custom flow-based features extracted from PCAPs (CSV)
│   └── dataset_arff_features/     # ARFF features provided by dataset authors
│
├── model_configurations/          # Model definitions and hyperparameters
│   ├── random_forest.py
│   ├── svm.py
│   └── xgb.py
│
|── results/
│
├── RF/
│   ├── rf_results_base_features/     # Results using custom flow-based features
│   └── rf_results_arff_features/     # Results using ARFF features
│
├── SVM/
│   ├── svm_results_base_features/    # Results using custom flow-based features
│   └── svm_results_arff_features/    # Results using ARFF features
│
└── XGBoost/
|    ├── xgb_results_base_features/    # Results using custom flow-based features
|    └── xgb_results_arff_features/    # Results using ARFF features
│
├── src/                               # Data extraction
```

## Dataset

The project uses the **ISCX VPN-nonVPN** dataset, provided by the Canadian Institute for Cybersecurity (University of New Brunswick). This dataset is widely used in the literature for evaluating encrypted network traffic classification methods.

The traffic is generated by running real applications in controlled environments and is captured as encrypted network packets (PCAP / PCAPNG files). The dataset includes multiple application categories such as:

- Streaming media (e.g., Spotify, YouTube, Netflix)
- Chat applications
- VoIP
- File transfer
- Peer-to-peer (P2P)
- Web browsing
  
<img width="838" height="466" alt="tipuri_trafic" src="https://github.com/user-attachments/assets/22b8b865-3b45-4aea-a7b4-16d758e6b3b7" />

 > Figure: Database representation.

Each application is available in both **VPN** and **non-VPN** scenarios.

For this project, we use the following subset of the dataset:
All PCAP files corresponding to **Spotify** traffic are labeled as the **positive class**, while traffic from all other applications is grouped into a single **negative class** (non-Spotify). 
For the negative class we impemented 2 scenarios:
- one where the rest of the traffic is composed of all the apps and traffic types available in the dataset
- the other using only applications that are included in the Streaming type of traffic (e.g. Netflix, Vimeo, Youtube).

## Methodology

The project evaluates **two distinct experimental scenarios** in order to analyze the
impact of feature representation on encrypted traffic classification performance.

Both scenarios address the same binary classification task:

- **Positive class**: Spotify traffic  
- **Negative class**: Non-Spotify traffic  

However, they differ in how features are obtained and represented.

### Scenario 1: Custom Flow-Based Feature Extraction

In the first scenario, features are **manually extracted from raw PCAP files** using a
custom pipeline implemented in this repository.

#### Flow Construction

Packets are aggregated into flows based on the standard 5-tuple:
- Source IP
- Destination IP
- Source port
- Destination port
- Transport protocol

A fixed-window flow strategy is used:
- **Window size**: 15s and 60s
- **Idle timeout**: 600s

Each flow window is treated as an independent sample.

#### Extracted Features

For each flow, a set of **statistical and temporal features** is computed, including:

- Flow duration
- Total packet count
- Total bytes
- Bytes A→B and B→A
- Mean packet length
- Inter-Arrival Time (IAT) standard deviation
- IAT kurtosis
- Packet length skewness
- Direction ratio (initiator vs. responder traffic)

The resulting dataset is stored in **CSV format** and used to train classical
machine learning models.

This scenario allows full control over:
- Feature design
- Flow aggregation strategy
- Window size and temporal granularity

### Scenario 2: ARFF Features Provided by Dataset Authors

In the second scenario, the project evaluates classification performance using
**ARFF feature files provided directly by the dataset authors**.

These features are:
- Pre-extracted by the creators of the ISCX VPN-nonVPN dataset
- Computed at flow level
- Designed according to methodologies commonly used in the literature

The ARFF files contain a rich set of statistical flow descriptors, including
packet size statistics, timing information, and direction-based metrics.

Unlike Scenario 1:
- No custom feature extraction is performed
- PCAP files are not reprocessed
- Features are loaded directly from ARFF files and converted for model training

This scenario serves as a **baseline comparison** against an established,
author-defined feature representation.

## Feature Extraction

Packets are aggregated into **flows** using a fixed-window approach (15s and 60s to match the arff data extracted by the authors). A flow is defined using a standard 5-tuple:

- Source IP  
- Destination IP  
- Source port  
- Destination port  
- Transport protocol  

Flows are closed and emitted when:
- the predefined window duration is reached
- an inactivity period exceeds the idle timeout - 600s according to the literature.

### Flow Parameters

- **Default window size**: 15 seconds  
- **Alternative window size**: 60 seconds  
- **Idle timeout**: 600 seconds  

Experiments are conducted using both 15s and 60s windows to analyze the impact of temporal aggregation on classification performance.

### Extracted Features

For each flow, the following statistical and temporal features are computed and stored in CSV format:

- Flow ID (hash-based identifier)
- Flow duration
- Total number of packets
- Total number of bytes
- Bytes sent from initiator to responder (A→B)
- Bytes sent from responder to initiator (B→A)
- Average packet length
- Inter-Arrival Time (IAT) standard deviation
- IAT kurtosis
- Packet length skewness
- Direction ratio (proportion of packets sent by the initiator)

Each flow window is treated as an independent sample in the dataset.

## Model details

The following classical machine learning models are evaluated:

### Support Vector Machine (SVM)

- Margin-based classifier
- Effective for high-dimensional feature spaces
- Uses kernel functions to handle non-linear separability

### Random Forest (RF)

- Ensemble method based on decision trees
- Uses bagging to reduce overfitting
- Robust to noisy and correlated features

### XGBoost

- Gradient boosting framework over decision trees
- Includes explicit regularization
- Strong performance on structured, tabular data

## Requirements
- Python 3.10 or later  
- PyTorch  
- NumPy, SciPy, Matplotlib 
- Scapy

## Installation

**Clone the repository:**

```
git clone https://github.com/Tsimina/PICSC.git
cd Medical-Image-Diagnosis
```

**Create and activate a virtual environment (optional)**

```
python -m venv venv
source venv/bin/activate    # Linux/macOS
venv\Scripts\activate.bat   # Windows
```

**Install dependencies**
```
pip install -r requirements.txt
```

## Usage

Get the according pcap files from the dataset.

> [!TIP]
> For a more accurate results we suggest doing the binary classification using applications that have the same type of traffic (e.g. Streaming, VoIP etc.).

**Get training dataset**
```
cd src
python build_dataset.py --pcap_dir ./pcap_director --out dtaset_csv --timeout 15.0/60.0 --nonspotify_ratio 1.0/2.0
```
> [!NOTE]
> The --nonspotify_ratio argument controls the ratio for balancing the dataset.

**Train**

To train your own model you just need to update with the paths to your dataset and results, depending on the target you want to achive you can also change the hyperparameters.

To start the training process run the following command:

```
cd model_configurations
python random_forest.py/svm.py/xgb.py
```

## Performance

This section summarizes the classification performance of each model under different
flow aggregation windows. Results are reported on **balanced datasets**
(Spotify : Non-Spotify = 1 : 1), using grouped cross-validation.

Two experimental scenarios are evaluated:
- **Base Features** – custom flow-based features extracted from PCAP files
- **ARFF Features** – pre-extracted features provided by the dataset authors

Unless explicitly stated otherwise, the results below refer to the **Base Features scenario**.

## Support Vector Machine (SVM)

### All Applications (Base Features)

#### 15s Flow Window (Idle Timeout = 600s)

| Metric    | Value |
|-----------|-------|
| Accuracy  | 82.44% |
| Precision | 0.87 |
| Recall    | 0.77 |
| F1-score  | 0.81 |

**Best configuration:**  
- Kernel: Linear  
- PCA components: 28  
- C: 1  

#### 60s Flow Window (Idle Timeout = 600s)

| Metric    | Value |
|-----------|-------|
| Accuracy  | 86.24% |
| Precision | 0.86 |
| Recall    | 0.87 |
| F1-score  | 0.87 |

**Best configuration:**  
- Kernel: RBF  
- PCA components: 28  
- C: 1  

## Random Forest (RF)

### All Applications (Base Features)

#### 15s Flow Window (Idle Timeout = 600s)

| Metric    | Value |
|-----------|-------|
| Accuracy  | 94.87% |
| Precision | 0.96 |
| Recall    | 1.00 |
| F1-score  | 0.98 |

**Best configuration:**  
- Estimators: 30  
- Max depth: 8  
- Min samples split: 5  
- Max features: log2  

#### 60s Flow Window (Idle Timeout = 600s)

| Metric    | Value |
|-----------|-------|
| Accuracy  | **95.68%** |
| Precision | **0.97** |
| Recall    | **1.00** |
| F1-score  | **0.98** |

**Best configuration:**  
- Estimators: 15  
- Max depth: 8  
- Min samples split: 2  
- Max features: sqrt  

## XGBoost

### All Applications (Base Features)

#### 15s Flow Window (Idle Timeout = 600s)

| Metric    | Value |
|-----------|-------|
| Accuracy  | 92.71% |
| Precision | 0.91 |
| Recall    | 0.95 |
| F1-score  | 0.93 |
| AUC       | 0.976 |

#### 60s Flow Window (Idle Timeout = 600s)

| Metric    | Value |
|-----------|-------|
| Accuracy  | 91.91% |
| Precision | 0.91 |
| Recall    | 0.93 |
| F1-score  | 0.92 |
| AUC       | 0.958 |

## Model Comparison – Base Features (All Applications)

### 15s Flow Window

| Model | Accuracy | Precision | Recall | F1-score |
|------|----------|-----------|--------|----------|
| SVM  | 82.44% | 0.87 | 0.77 | 0.81 |
| RF   | **94.87%** | **0.96** | **1.00** | **0.98** |
| XGB  | 92.71% | 0.91 | 0.95 | 0.93 |

### 60s Flow Window

| Model | Accuracy | Precision | Recall | F1-score |
|------|----------|-----------|--------|----------|
| SVM  | 86.24% | 0.86 | 0.87 | 0.87 |
| RF   | **95.68%** | **0.97** | **1.00** | **0.98** |
| XGB  | 91.91% | 0.91 | 0.93 | 0.92 |

## ARFF Feature Results (Author-Provided Features)

### Best Results – All Applications

| Model | Flow Window | Accuracy | Precision | Recall | F1-score |
|------|-------------|----------|-----------|--------|----------|
| SVM  | 15s | 84.46% | 0.76 | 1.00 | 0.87 |
| SVM  | 60s | 86.86% | 0.83 | 0.95 | 0.89 |
| RF   | 15s | 85.99% | 0.79 | 1.00 | 0.88 |
| RF   | 60s | **89.59%** | **0.84** | **1.00** | **0.91** |
| XGB  | 15s | 64.98% | 0.66 | 0.62 | 0.64 |
| XGB  | 60s | 66.72% | 0.67 | 0.66 | 0.66 |

## Base Features vs. ARFF Features – Best Configuration

| Feature Scenario | Best Model | Flow Window | Accuracy |
|------------------|------------|-------------|----------|
| Base Features | Random Forest | 60s | **95.68%** |
| ARFF Features | Random Forest | 60s | 89.59% |

## Performance Interpretation: All Data vs. Streaming-Only Data

The **highest classification performance** is consistently obtained when training and
testing on **all application traffic**, not only on streaming applications.

- Base Features clearly outperform ARFF features in all configurations
- Random Forest is the most robust model across both scenarios
- XGBoost benefits strongly from custom feature engineering
- Larger flow windows (60s) improve recall and stability

## Streaming-Only Dataset Performance

When restricting the dataset to **streaming applications only**
(Spotify, Netflix, YouTube, Vimeo):

- Overall accuracy decreases for both feature scenarios
- Traffic patterns are more similar, reducing class separability
- Accuracy typically falls in the **60–80% range**

This confirms that **Spotify traffic is most distinguishable when contrasted against a diverse set of applications**, rather than against other streaming services.

## Summary

| Dataset Configuration | Feature Type | Observed Performance |
|----------------------|-------------|----------------------|
| All applications | Base Features | **Best performance (~96%)** |
| All applications | ARFF Features | Good baseline (~90%) |
| Streaming-only | Any features | Lower performance |

**Final takeaway:**  
> Custom flow-based feature engineering provides a significant performance advantage over standardized ARFF features.

## Limitations

- Only classical machine learning models were evaluated
- Deep learning approaches (e.g., CNNs, GNNs) were not implemented
- The classification task is limited to binary classification (Spotify vs. rest)

### Future Work

- Extend to multi-class traffic classification
- Evaluate deep learning models on raw packet or flow representations
- Explore real-time traffic classification
- Test robustness across different datasets and network conditions

## Acknowledgments

**Contributors**  
- Manolache Arianna  
- Stroe Teodora-Simina  

This project was developed as part of an **Integrated Project in Cybersecurity**.


